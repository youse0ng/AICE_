{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPQtMko915jpn/QtTY5P7HE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youse0ng/AICE_/blob/main/AICE_08_%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5%EC%9C%BC%EB%A1%9CAI%EB%AA%A8%EB%8D%B8%EB%A7%81%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 머신러닝으로 AI 모델링하기"
      ],
      "metadata": {
        "id": "CcpFLEqTl159"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 사이킷런 라이브러리\n",
        "\n",
        "머신러닝의 대표적인 라이브러리이며 사이킷런 라이브러리 기반 학습 및 예측 패턴의 4단계에서 실행 명령어의 예시는 다음과 같다.\n",
        "\n",
        "1. 불러오기 (from sklearn.ensemble import RandomRorestClassifier)\n",
        "2. 생성 clf=RandomForestClassifier(random_state=0)\n",
        "3. 학습 clf.fit(X,y)\n",
        "4. 예측 clf.predict(X)\n",
        "\n",
        "이 4단계로 머신러닝 모델 개발이 완료된다."
      ],
      "metadata": {
        "id": "df0EORtnmWb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 선형 회귀"
      ],
      "metadata": {
        "id": "oVGBBJpLnE5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 선형 회귀 이해하기\n",
        "\n",
        "주식 같은 시계열 데이터의 그래프를 분석할 때 많이 쓰는 용어 중에 '추세선'이 있다.\n",
        "\n",
        "추세선은 데이터의 추세를 그래프를 표현하여 이후의 패턴을 예측하는데 활용된다.  \n",
        "\n",
        "이러한 통계 분석 방식을 회귀 분석이라고 한다.\n",
        "\n",
        "우리가 학습해야 하는 머신러닝은 주어진 데이터를 바탕으로 label(Y)과 feature(X)의 관계를 가장 잘 설명하는 모델을 만드는 것이고, 그 모태가 되는 알고리즘, 즉 최적의 직서늘 기반으로 예측하는 방법이 선형 회귀이다.\n",
        "\n"
      ],
      "metadata": {
        "id": "U0srkXU7nE3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 선형 회귀 실습하기\n",
        "\n",
        "선형 회귀 알고리즘은 sklearn의 linear_model 서브 패키지에서 제공하는 LinearRegression 클래스를 활용할 수 있다.\n",
        "\n",
        "LinearRegression 클래스는 다음과 같은 하이퍼파라미터를 입력받는다.\n",
        "\n",
        "\n",
        "- fit_intercept: 절편값의 계산 여부 지정\n",
        "\n",
        "학습이 끝나면 모델은 다음 속성을 가진다.\n",
        "\n",
        "- coef_: 학습된 모델 특성의 가중치 추정값\n",
        "- intercept_: 학습된 모델의 절편 추정값\n"
      ],
      "metadata": {
        "id": "lXX_MZ15n2ci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터 구성하기\n",
        "\n",
        "데이터는 y=4x+7이고, x의 입력할 데이터는 1~10이다.\n",
        "y=4x+7로 출력된 결과이기 때문에,\n",
        "해당 데이터를 학습한 모델이 핵심 숫자 2개(4와 7)를 기울기(coef) 및 절편(intercept)으로 지니는 모델이라면 학습이 잘 되었다고 판단할 수 있다.\n"
      ],
      "metadata": {
        "id": "YUKWs07In49L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(2023)\n",
        "\n",
        "# x는 1~10, y=4x+7인 학습 데이터 생성하기\n",
        "x=[]\n",
        "y=[]\n",
        "\n",
        "for i in range(1,11):\n",
        "  x.append(i)\n",
        "  y.append(4*i+7)\n",
        "\n",
        "# 데이터 확인하기\n",
        "print('x : ', x)\n",
        "print('y : ', y)"
      ],
      "metadata": {
        "id": "fTwC9GUvovyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 선형 회귀 학습하기"
      ],
      "metadata": {
        "id": "ujUxQADRp8fR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 선형 회귀 생성하기\n",
        "reg=LinearRegression()\n",
        "\n",
        "# 학습을 위해 1행 10열 구성 데이터를 10행 1열로 변경하기\n",
        "x=np.array(x)\n",
        "print(x)\n",
        "x=x.reshape(-1,1)"
      ],
      "metadata": {
        "id": "ToUZQ5fWp8cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습하기\n",
        "reg.fit(x,y)\n",
        "\n",
        "# 산식 추정을 위한 기울기(coef) 및 절편(intercept) 확인하기\n",
        "print(f'''기울기 및 절편 확인 coef={reg.coef_},intercept={reg.intercept_}''')\n",
        "\n",
        "# 절편과 기울기로 결과를 수동 계산하여 비교값 생성하기\n",
        "coef_intercept=x*reg.coef_[0]+reg.intercept_\n",
        "print('계산결과')\n",
        "print(coef_intercept)"
      ],
      "metadata": {
        "id": "B8C06sWrnE1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.coef_[0],reg.intercept_"
      ],
      "metadata": {
        "id": "1L0mqsFsrqQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 결과 비교를 위한 그래프 그리기"
      ],
      "metadata": {
        "id": "qHz8oUniuzDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scatter plot 그래프 그리기\n",
        "plt.scatter(x,y,color='r',s=20)\n",
        "\n",
        "# 선 그래프 그리기\n",
        "plt.plot(x,coef_intercept,color='orange')\n",
        "\n",
        "# coef 값 그래프 내에 텍스트 삽입하기\n",
        "plt.text(7,20,'coef=%.0f'%reg.coef_[0],size=12)\n",
        "\n",
        "# intercept 값 그래프 내ㅔ 텍스트 삽입\n",
        "plt.text(7,18,'intercept_=%.0f'%reg.intercept_,size=12)\n",
        "\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UgiTW_cwnEzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 사례 기반 선형 회귀 모델링\n",
        "\n",
        "국민건강보험공단_건강검진정보_20211229.csv 사용\n",
        "\n",
        "키, 몸무게 등 다양한 데이터 중에 추론을 통해 예측했을 때, 유의미한 결과를 가져올 만한 변수를 찾아봅니다.\n",
        "\n",
        "콜레스테롤 중 LDL 콜레스테롤은 건강에 좋지 않은 수치이기에 건강 검진에서 필요할 확률이 매우 높다. 이에 건강검진 데이터를 바탕으로 LDL 콜레스테롤의 수치를 예측해보는 선형 회귀 모델을 개발한다면 도움이 될 것이다.\n",
        "\n",
        "따라서 해당 결과를 도출하는 모델을 간단히 만들어 봅니다.\n",
        "\n",
        "우선 간단한 가설로 데이터 중에 치아 관련 문항은 콜레스테롤과 상관 없을 것이라는 가설을 세워서 실습을 진행하고 가중치를 확인해 봅니다.\n",
        "\n",
        "모델링에 앞서 모델링을 위한 데이터를 전처리한다.\n",
        "\n"
      ],
      "metadata": {
        "id": "9Vgy1z5nnEth"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 전처리"
      ],
      "metadata": {
        "id": "S9soUbbAnEoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터 불러오기\n",
        "df=pd.read_csv(\"/content/HP_SCR_2020.CSV\",encoding='cp949')\n",
        "\n",
        "# pandas display 옵션 조정을 통해 View 범위 확정하기\n",
        "pd.set_option('display.max_columns',None) # display 옵션을 통한 전체 열 확장\n",
        "\n",
        "# 데이터 확인하기\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "JgUSagQ2nElp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가설을 참고하여 (치아와 관련된 문항+ 시력,청력) 데이터 컬럼 삭제\n",
        "# 시력 청력 치아 관련 칼럼은 관계없다라는 가정으로 열 제거\n",
        "df.drop(labels=[\"시력(좌)\",\"시력(우)\",\"청력(좌)\",\"청력(우)\",\"치석\",\"구강검진 수검여부\",\"치아우식증유무\"],axis=1,inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "C-utQx09nEeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기준년도 칼럼 확인하기(모두 '2020' 동일 값이므로 '기준년도' 칼럼 삭제)\n",
        "df['기준년도'].value_counts()\n",
        "df.drop(['기준년도','데이터 공개일자'],axis=1,inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "jghbmouznEYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가입자 일련번호 확인하기 (모두 unique한 값으로 확인되어 `가입자 일련번호` 칼럼 삭제)\n",
        "\n",
        "print(\"가입자 일련번호 칼럼 확인\")\n",
        "df[\"가입자 일련번호\"].value_counts()\n",
        "\n",
        "df.drop([\"가입자 일련번호\"],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "uH7FQOi5uYjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "84eqQSbHuYgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"성별코드 칼럼 확인\")\n",
        "df.성별코드.value_counts()"
      ],
      "metadata": {
        "id": "nA6smlMHuX6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['성별코드','시도코드'],axis=1, inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "IAu7YhSXnEDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 별도의 test 데이터 추출하기\n",
        "test=df[df['LDL 콜레스테롤'].isnull()] # LDL 콜레스테롤 칼럼이 NaN 값인 데이터 프레임 추출\n",
        "test\n",
        "\n",
        "# NaN 데이터 행 단위로 삭제하기\n",
        "train=df.dropna(axis=0)\n",
        "\n",
        "# 학습 데이터 확인하기\n",
        "print('학습데이터 확인')\n",
        "train.head()"
      ],
      "metadata": {
        "id": "Mo1XLErzsMXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "kEUXwOuZfocE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정답 데이터 생성하기\n",
        "y=train['LDL 콜레스테롤']\n",
        "\n",
        "# 학습 데이터 생성하기\n",
        "x=train.drop(['LDL 콜레스테롤'],axis=1)\n",
        "\n",
        "# validation set 추출을 위한 train_test_split 라이브러리 불러오기\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# scikit learn에서 코드 비율대로 불러오기\n",
        "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.33,random_state=42)\n",
        "\n",
        "# 학습/검증 데이터 확인\n",
        "print(\"학습/검증데이터 확인\")\n",
        "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
      ],
      "metadata": {
        "id": "GI8t3kqxsMU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(range(3)))"
      ],
      "metadata": {
        "id": "W1d-ffMhxLYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 선형 회귀 학습 및 추론하기"
      ],
      "metadata": {
        "id": "AHGl9S3MsMS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 불러오기\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 모델 생성하기\n",
        "reg=LinearRegression()\n",
        "\n",
        "# 학습하기\n",
        "reg.fit(X_train,y_train)\n",
        "\n",
        "# 기울기와 절편\n",
        "print(f\"\"\"\n",
        "기울기 및 절편확인\n",
        "기울기 확인 coef={reg.coef_}\n",
        "절편 확인 intercept={reg.intercept_}\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "eA6J-vBUsMQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각각 데이터에 대해 가중치(or 회귀계수) 확인하기\n",
        "print(\"전체에 대해서 가중치 확인\")\n",
        "q=[]\n",
        "for index,columns in enumerate(X_train.columns):\n",
        "  print(f\"{columns} = {reg.coef_[index]}\")\n",
        "  q.append(f\"{columns} = {reg.coef_[index]}\")\n",
        "\n",
        "print(f\"q={q}\")"
      ],
      "metadata": {
        "id": "jBoDoU8isMO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "가중치가 높다는 것은 그만큼 y 영향을 많이 준다는 의미이다.\n",
        "\n",
        "주요 Feature 3개 {총 콜레스테롤, HDL콜레스테롤, 음주여부}\n"
      ],
      "metadata": {
        "id": "Rh8_HWgXIb0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 예측을 통한 최종 검증하기"
      ],
      "metadata": {
        "id": "GqS2hhaOsMNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측하기\n",
        "y_pred=reg.predict(X_test)\n",
        "\n",
        "# 결과 검증을 위해 MSE 라이브러리 불러오기\n",
        "# 최종적으로는 RMSE 사용하기\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# MSE 라이브러리에서 RMSE는 squared 옵션을 False로 설정한다\n",
        "rmse=mean_squared_error(y_test,y_pred,squared=False)\n",
        "\n",
        "# 주요 Feature 삭제 전 rmse 확인하기\n",
        "print(f\"\"\"주요 Feature 삭제 전 rmse={round(rmse,3)}\"\"\")"
      ],
      "metadata": {
        "id": "LkfNKQE6sMLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "주요 feature 들은 삭제 해보고 RMSE 값이 어떻게 나오는지 확인해보자"
      ],
      "metadata": {
        "id": "kyM1-BaksMJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 가중치의 의미 확인하기"
      ],
      "metadata": {
        "id": "fo2YMMY-cPUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 주요 Feature 삭제를 위해 칼럼명 재확인\n",
        "train.columns"
      ],
      "metadata": {
        "id": "NO63tq5BsMHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "ZiaGZgJ7eZyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 주요 Feature 삭제하기\n",
        "x=x.drop(['총 콜레스테롤','트리글리세라이드','HDL 콜레스테롤'],axis=1)\n",
        "\n",
        "# scikit learn 예시 코드 비율대로 불러오기\n",
        "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.33,random_state=42)"
      ],
      "metadata": {
        "id": "x_MF_h4WcWOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 선형 회귀 모델 재학습하기"
      ],
      "metadata": {
        "id": "SmIW9UQZcWMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 선형 회귀 재생성 및 학습하기\n",
        "lr=LinearRegression()\n",
        "lr.fit(X_train,y_train)\n",
        "\n",
        "# 각각 데이터에 대해 가중치(또는 회귀 계수) 확인하기\n",
        "print(f'''coef\n",
        "{lr.coef_}\n",
        "intercept\n",
        "{lr.intercept_}''')"
      ],
      "metadata": {
        "id": "JU2bRmT0cWKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 가중치 비교하기"
      ],
      "metadata": {
        "id": "irXIyCx2cWFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증 데이터로 예측하기\n",
        "y_pred=lr.predict(X_test)\n",
        "\n",
        "# 각각 데이터에 대해 가중치 (또는 회귀 계수) 확인하기\n",
        "print('가중치 확인')\n",
        "for index,columns in enumerate(X_train.columns):\n",
        "  print(f\"{columns}={lr.coef_[index]}\")"
      ],
      "metadata": {
        "id": "9S9wEsqOcWEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 주요 Feature 삭제 후 RMSE 확인하기\n",
        "rmse2=mean_squared_error(y_test,y_pred,squared=False)\n",
        "\n",
        "# 가중치가 큰 특성을 삭제했을 때 영향을 많이 받는지 확인하기\n",
        "print(f''' 주요 Feature 삭제 후 rmse={round(rmse2,3)}''')\n"
      ],
      "metadata": {
        "id": "AmIpXq1xcWB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 로지스틱 회귀 모델\n"
      ],
      "metadata": {
        "id": "RfCevPepcWAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 로지스틱 회귀 이해하기\n",
        "\n",
        "로지스틱 회귀 모델은 시그모이드 함수를 사용하여 데이터를 설명하는 최저긔 선으로\n",
        "답을 찾는 알고리즘이다.\n",
        "\n",
        "다만, 이름에 회귀가 있으나 분류에 사용되는 알고리즘입니다.\n",
        "\n",
        "로지스틱 회귀 알고리즘의 산식은\n",
        "\n",
        "S(x) =1/(1+e^-x) 입니다.\n"
      ],
      "metadata": {
        "id": "BIaq8s3ocV-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 시그모이드 함수 만들기"
      ],
      "metadata": {
        "id": "tw8s3sepcV8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy 라이브러리 및 그래프 라이브러리 불러오기\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sigmoid 함수 작정하기\n",
        "def sigmoid(x):\n",
        "\n",
        "  # numpy.exp() 함수는 미티 자연상수 e인 지수함수(e^x)로 변환\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "# 함수 테스트용 데이터 생성하기\n",
        "test=np.array([-1,0,1])\n",
        "\n",
        "# 작성된 함수 확인하기\n",
        "print(sigmoid(test))"
      ],
      "metadata": {
        "id": "xBScIl8zcV68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 시그모이드 함수 그래프 그리기"
      ],
      "metadata": {
        "id": "JRNYJXILcV4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프 적용을 위한 데이터 만들기\n",
        "sigmoid_x=range(-6,7)\n",
        "sigmoid_y=sigmoid(np.array(sigmoid_x))\n",
        "\n",
        "# 선 그래프 그리기\n",
        "plt.plot(sigmoid_x,sigmoid_y,color='blue',linewidth=0.5)\n",
        "\n",
        "# 백 그라운드 모눈 종이 설정하기\n",
        "plt.rcParams['axes.grid']=True\n",
        "\n",
        "# 선 긁기 설정하기\n",
        "plt.axvline(x=0,color='black',linewidth=3)\n",
        "\n",
        "# y축 범위 설정하기\n",
        "plt.yticks([0,0.5,1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "odhEXvKacV2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 로지스틱 회귀 실습하기\n",
        "왜 로지스틱 회귀 모델을 학습하고 왜 분류 문제에서 선형 회귀 모델보다 로지스틱 회귀가 더 작합한지 살펴보자.\n",
        "\n",
        "로지스틱 회귀 알고리즘은 sklearn의 linear_model 서브패키지에서 제공하는 LogisticRegression 클래스로 활용할 수 있다.\n",
        "\n",
        "하이퍼파라미터:\n",
        "- max_iter: 알고리즘의 수렴을 위한 반복의 최대 횟수\n",
        "- penalty: 규제의 종류 선택('l1','l2','elasticnet','none')\n",
        "- C: 규제의 강도를 조절하는 파라미터로 값이 클수록 규제가 약해지고 값이 작을수록 규제가 강해짐\n",
        "\n",
        "학습이 끝나면 객체는 다음속성을 가짐\n",
        "- LogisticRegression.coef_: 학습된 모형 특성의 가중치 추정값\n",
        "- LogisticRegression.intercept_: 학습된 모델의 절편 추정값\n"
      ],
      "metadata": {
        "id": "Y-aaKDCacV0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터 구성하기"
      ],
      "metadata": {
        "id": "AgEkmCEscVy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습데이터 생성하기\n",
        "x_train=[3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]\n",
        "y_train=[0,0,0,0,0,0,0,1,1,1,1,1,1,1,1]\n",
        "\n",
        "# 추론을 위한 데이터 생성하기\n",
        "x_test=[0,1,2,18,19]\n",
        "y_test=[0,0,0,1,1]\n",
        "\n",
        "# 학습 데이터에 대해 numpy로 변경 및 행을 열로 변경하기\n",
        "x_train=np.array(x_train).reshape(-1,1)\n",
        "y_train=np.array(y_train)\n",
        "\n",
        "# 추론 데이터에 대해 numpy로 변경 및 행을 열로 변경하기\n",
        "x_test=np.array(x_test).reshape(-1,1)\n",
        "y_test=np.array(y_test)\n",
        "\n",
        "# 데이터 확인하기\n",
        "print(x_train)\n",
        "print(y_train)"
      ],
      "metadata": {
        "id": "mDCFVK1rcVxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "x_train 데이터 값이 9에서 10으로 넘어갈 때, y_train 데이터값이 0에서 1로 변하는 데이터를 준비"
      ],
      "metadata": {
        "id": "cE6FyNbOcVvH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 로지스틱 회귀 학습하기\n"
      ],
      "metadata": {
        "id": "h0hOSnPBcVt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 로지스틱 회귀 라이브러리 불러오기\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 로지스틱 회귀 생성하기\n",
        "logi_reg=LogisticRegression()\n",
        "\n",
        "# 학습하기\n",
        "logi_reg.fit(x_train,y_train)\n",
        "\n",
        "# 역산을 위한 기울기와 절편이 있는지 확인\n",
        "print('intercept: ',logi_reg.intercept_)\n",
        "print('coef: ', logi_reg.coef_)"
      ],
      "metadata": {
        "id": "AZeHPUTscVqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 로지스틱 회귀 그래프 만들기\n"
      ],
      "metadata": {
        "id": "Vjfkv9t1tVTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 기울기와 절편을 수동으로 결과 만들기\n",
        "odd=[] #\n",
        "for i in x_train:\n",
        "  odd.append((logi_reg.coef_*i) + logi_reg.intercept_)\n",
        "\n",
        "print(odd)\n",
        "\n",
        "sigmoid_y=sigmoid(np.array(odd))\n",
        "sigmoid_y=sigmoid_y.reshape(-1,1)\n",
        "\n",
        "# 역산된 그래프 표시하기\n",
        "plt.scatter(x_train,y_train,color='red')\n",
        "plt.plot(np.array(x_train),sigmoid_y,color='blue')\n",
        "plt.rcParams['axes.grid']=True\n",
        "plt.yticks([0,0.5,1])\n",
        "plt.ylim([-0.1,1.1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Uj0bwMFzutd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([3,4,5,6,7,8,9,10,11,12,13,14,15,16,17],np.array(odd).squeeze(),color='green')\n",
        "plt.xlabel('x_train')\n",
        "plt.ylabel('predict_from_Logi_model')"
      ],
      "metadata": {
        "id": "x44khaCR3ihD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "coef와 intercept를 이용하여 그린 sigmoi 그래프가 데이터를 잘 표현하고 있음을 확인\n",
        "\n",
        "지금부터는 선형 회귀와 로지스틱 회귀를 비교해서 두 모델 모두 같은 선형으로 모델링을 하지만 왜 선형 회귀는 수치를 예측하는 회귀 모델에, 로지스틱 회귀는 범주형 데이터를 예측하는 분류 모델에 더 적합한지 알아보자"
      ],
      "metadata": {
        "id": "aox30wG3cVoS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 로지스틱 회귀와 선형 회귀 비교하기"
      ],
      "metadata": {
        "id": "s6R57fA7sMF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 선형 회귀 모델링하기"
      ],
      "metadata": {
        "id": "26kTzPn3LJWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 선형 회귀 함수 불러오기\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 선형 회귀 생성하기\n",
        "lr=LinearRegression()\n",
        "\n",
        "# 학습하기\n",
        "lr.fit(x_train,y_train)\n",
        "\n",
        "# 수식 완성을 위한 coef와 intercept 확인하기\n",
        "print('intercept: ', lr.intercept_)\n",
        "print('coef_: ',lr.coef_)"
      ],
      "metadata": {
        "id": "jr2Fa-f3LMPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 선형 회귀 모델과 로지스틱 회귀 모델 비교하기"
      ],
      "metadata": {
        "id": "KXKIS4dcLML9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coef_intercept=x_train * lr.coef_ +lr.intercept_\n",
        "\n",
        "plt.scatter(x_train,y_train,color='red')\n",
        "plt.plot(np.array(x_train),coef_intercept,color='green')\n",
        "plt.plot(np.array(x_train),sigmoid_y,color='blue')\n",
        "plt.rcParams['axes.grid']=True\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tuOHl6mHLMIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "로지스틱 회귀는 Y축의 0.5(임계값 변경 가능)을 기준으로 yes 또는 No를 구분하여 이진/다중 분류에 강한 모델을 만든다.\n",
        "반면 선형 회귀는 직선으로만 참 거짓을 구분한다.\n",
        "\n",
        "위 학습 모델을 기반으로 예측할 때 9.5라는 데이터를 학습 모델에 넣는다면 어떤 결과가 나올까?\n"
      ],
      "metadata": {
        "id": "sQ8kC8jiLMBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logi_pred=logi_reg.predict(np.array(9.5).reshape(-1,1))\n",
        "print(f\"로지스틱 회귀 분석 예측:{logi_pred}\")\n",
        "\n",
        "lr_pred=lr.predict(np.array(9.5).reshape(-1,1))\n",
        "print(f'선형 회귀 분석 예측:{round(lr_pred[0])}')\n"
      ],
      "metadata": {
        "id": "H7c4ws0gLL9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 의사결정나무\n"
      ],
      "metadata": {
        "id": "ny2167wgLL5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 의사결정나무 이해하기\n",
        "\n",
        "지금부터는 트리 기반 알고리즘을 알아봅니다. 트리 기반 모델은 기본적으로 Feature를 조건 기반으로 참 거짓으로 나눠 마치 스무고개를 하듯이 학습을 이어나갑니다.\n",
        "\n",
        "예를 들어, 시장에서 물건을 구매할 때, 사과,고기, 야채를 산다고 가정한다.\n",
        "맨 처음 과일가게에서 '사과를 사면 다른 물건을 전부 살 수 있을까?' 라는 고민을 하게 된다. 내가 가진 자원(DATA)과 각 물건의 중요도(WEIGHT)를 기반으로 구매 여부(LABEL)을 비교하면서 고기와 야채를 살 것입니다.\n",
        "\n",
        "최종적으로, 사과를 구매하는 단계까지 과정을 보면 사람이 의사결정을 하는 것과 유사하다.\n",
        "\n"
      ],
      "metadata": {
        "id": "OQl3mtXbQ3S5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 의사결정나무 실습하기\n",
        "\n",
        "건강검진 데이터를 가지고 음주여부를 성별, 키, 체중데이터를 기반으로 의사결정나무를 학습하고, 결과를 통해 의사결정나무의 원리를 알아보자.\n",
        "\n",
        "sklearn의 tree 서브패키지 DecisionTreeClassifier(DEcisionTreeRegressor)클래스로 활용할 수 있다.\n",
        "\n",
        "DecisionTreeclassifier의 파라미터\n",
        "\n",
        "- max_depth: 깊어질 수 있는 최대 깊이, 과대적합 방지용\n",
        "- max_features: 최대로 사용할 feature의 개수, 과대적합 방지요\n",
        "- min_samples_split: 트리의 노드가 가지고 있는 최소한의 샘플 수, 과대적합 방지용\n",
        "\n"
      ],
      "metadata": {
        "id": "f74OrvhqLL2W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터 준비하기"
      ],
      "metadata": {
        "id": "FyOgoxdMLLyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터 불러오기\n",
        "df=pd.read_csv(\"/content/HP_SCR_2020.CSV\", encoding='cp949')\n",
        "\n",
        "# 트리 예시를 만들기 위해 일부특성만 추출\n",
        "sample_df=df[['신장(5Cm단위)','성별코드','체중(5Kg 단위)','음주여부']]\n",
        "\n",
        "sample_df[:10]"
      ],
      "metadata": {
        "id": "lA-eh1inSf32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터 전처리하기"
      ],
      "metadata": {
        "id": "Gnh9Vg5dLLvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# info 정보로 결측치(Null) 확인하기\n",
        "print(\"Info 정보 확인\")\n",
        "sample_df.info()"
      ],
      "metadata": {
        "id": "pzDHCmQ4LLqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 백만개 데이터 중 196개 결측치가 포함된 행 삭제\n",
        "sample=sample_df.dropna()\n",
        "\n",
        "# 결측치 다시 확인\n",
        "print(\"Drop 후 Info 정보 확인\")\n",
        "sample.info()"
      ],
      "metadata": {
        "id": "fT-3YtgHLLlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원핫 인코딩을 위해 데이터 object형태로 변경하기\n",
        "sample=sample.astype('str')\n",
        "\n",
        "# label(결과,y) 생성하기\n",
        "y=sample.음주여부\n",
        "\n",
        "# 음주여부 학습 데이터 구성하기\n",
        "X=sample.drop('음주여부',axis=1)\n",
        "\n",
        "# label 데이터의 편향성 확인하기\n",
        "y.value_counts()"
      ],
      "metadata": {
        "id": "4UyAm-Nlclim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head(15)"
      ],
      "metadata": {
        "id": "_iin1FSgjJVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.head(15)"
      ],
      "metadata": {
        "id": "3gdTYSyvjOcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample.info()"
      ],
      "metadata": {
        "id": "SYtadbeHdkUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample.head()"
      ],
      "metadata": {
        "id": "mew7VHini-wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 검증 데이터 분리하기\n",
        "x_train,x_valid,y_train,y_valid=train_test_split(\n",
        "    X,y,\n",
        "    test_size=0.2,\n",
        "    shuffle=True,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "E0hQdAv9dyFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 의사결정나무 모델링하기"
      ],
      "metadata": {
        "id": "elk4aFqWeEZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://inuplace.tistory.com/548#:~:text=DecisionTreeClassifier%20%28%29%20criterion%20%3A%20%EB%B6%84%ED%95%A0%20%ED%92%88%EC%A7%88%EC%9D%84%20%EC%B8%A1%EC%A0%95%ED%95%98%EB%8A%94%20%EA%B8%B0%EB%8A%A5,%ED%8A%B8%EB%A6%AC%EC%9D%98%20%EC%B5%9C%EB%8C%80%20%EA%B9%8A%EC%9D%B4%20%28%EA%B0%92%EC%9D%B4%20%ED%81%B4%EC%88%98%EB%A1%9D%20%EB%AA%A8%EB%8D%B8%EC%9D%98%20%EB%B3%B5%EC%9E%A1%EB%8F%84%EA%B0%80%20%EC%98%AC%EB%9D%BC%EA%B0%84%EB%8B%A4.%29\n",
        "resource"
      ],
      "metadata": {
        "id": "GjMM96dMmZ9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 의사결정나무 모델 불러오기\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 의사결정나무 모델 생성하기\n",
        "dt=DecisionTreeClassifier(random_state=1001,\n",
        "                          max_depth=2\n",
        "                          )\n",
        "\n",
        "# 의사결정나무 학습하기\n",
        "dt_model=dt.fit(x_train,y_train)\n",
        "\n",
        "# 학습데이터 정확도확인\n",
        "print(\"학습 정확도: \",dt_model.score(x_train,y_train))\n",
        "\n",
        "# 검증데이터 정확도확인\n",
        "print(\"검증 정확도: \",dt_model.score(x_valid,y_valid))"
      ],
      "metadata": {
        "id": "lldEsZsBeEXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_weights=dt_model.feature_importances_\n",
        "\n",
        "features=x_train.columns\n",
        "for i in range(len(features)):\n",
        "  print(f\"{features[i]} = {feature_weights[i]}\")\n",
        "\n",
        "# 성별 코드가 제일 유의미한 weight 가중치임을 확인."
      ],
      "metadata": {
        "id": "sPntq27Ymgju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 의사결정나무 그래프 그리기(import graphviz)\n"
      ],
      "metadata": {
        "id": "feFWRV2IQq3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프 라이브러리 불러오기\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 트리모양 그래프 작성을 위한 라이브러리 설치하기\n",
        "#!pip install graphviz\n",
        "\n",
        "# 그래프 라이브러리 불러오기\n",
        "import graphviz\n",
        "\n",
        "# 사이킷런의 graphviz 지원 모듈 불러오기\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "# 그래프 생성하기\n",
        "tree_graph=graphviz.Source(export_graphviz(dt_model,max_depth=3,\n",
        "                                           feature_names=x_train.columns,\n",
        "                                           class_names=[\"O\",\"X\"],\n",
        "                                           impurity=True))\n",
        "\n",
        "# 그래프 파일 저장하기\n",
        "tree_graph.render(\"tree_depth5\",format='png')\n",
        "\n",
        "\n",
        "# 그래프 출력하기\n",
        "tree_graph"
      ],
      "metadata": {
        "id": "UXF4TsrDTXhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "시각화된 각 네모칸은 노드라고한다. 맨 처음 시작하는 노드를 나무의 뿌리라고 하여 루트 노드라고한다.\n",
        "\n",
        "각 노드에는 분할 조건, 지니계수, 입력된 샘플의 수, 각 Value별 count등이 있음.\n",
        "\n",
        "노드에 분할 조건이 없으면 리프 노드라고 한다.\n",
        "\n",
        "1. 성별코드 <= 1.5: 분할 조건\n",
        "2. gini: 지니계수\n",
        "3. samples: 입력된 데이터 개수\n",
        "4. value: 입력된 데이터에서의 각 Class 별 개수\n",
        "5. class: 리스트 내에서 가장 많은 데이터 value\n",
        "\n",
        "의사결정나무는 지니계수(불순도 지표)를 낮추는 방향으로 가지를 분할한다.\n",
        "\n"
      ],
      "metadata": {
        "id": "X9hX8hfpTXkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###불순도 알아보기\n",
        "\n",
        "지니계수는 불순도를 측정하는 지표로서, 데이터의 통계적인 분산의 정도를 정령화해서 표현한다.\n",
        "\n",
        "Gini: 1-sum(p^2)"
      ],
      "metadata": {
        "id": "bYiBw2hdk2It"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 불순도 함수 생성하기\n",
        "def gini(x):\n",
        "  n=x.sum()\n",
        "  gini_sum=0\n",
        "\n",
        "  for key in x.keys(): # 데이터프레임의 인덱스 숫자 뽑기\n",
        "    gini_sum=gini_sum+(x[key]/n)*(x[key]/n)\n",
        "    print(f\"x[key] = {x[key]}\")\n",
        "  gini=1-gini_sum\n",
        "\n",
        "  return gini\n",
        "\n",
        "# 데이터 준비하기\n",
        "과일바구니1=[\"사과\"]*9\n",
        "과일바구니2=[\"사과\",\"바나나\",\"사과\",'바나나','바나나','바나나','복숭아','복숭아','복숭아']\n",
        "과일바구니3=['사과','바나나','사과','바나나','사과','복숭아','복숭아','사과','복숭아']"
      ],
      "metadata": {
        "id": "Pe_TOChIk2G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(round(gini(pd.DataFrame(과일바구니1).value_counts()),3))"
      ],
      "metadata": {
        "id": "dlj4pd5dk2E5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(round(gini(pd.DataFrame(과일바구니2).value_counts()),3))"
      ],
      "metadata": {
        "id": "79OaHa3kqalE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(round(gini(pd.DataFrame(과일바구니3).value_counts()),3))"
      ],
      "metadata": {
        "id": "1NkCpcOJqafV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(과일바구니2).value_counts()[2]"
      ],
      "metadata": {
        "id": "zv-tG82Pk17g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 확인문제 1. max_depth 파라미터를 이용하여 1, 15, 30으로 각각의 모델을 만들어보고 validation score가 작은 max_depth 수치를 작성하세요. (Random_state=1001)\n"
      ],
      "metadata": {
        "id": "_BiAkglDk15e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample 확인\n",
        "sample"
      ],
      "metadata": {
        "id": "xx-bMMttumTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 음주여부 이외의 데이터 (학습 데이터 만들기)\n",
        "X=sample.drop(labels='음주여부',axis=1)\n",
        "X"
      ],
      "metadata": {
        "id": "gXK2b2JvuyQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정답 데이터 만들기\n",
        "y=sample[\"음주여부\"]\n",
        "y"
      ],
      "metadata": {
        "id": "IABlXH4UxMTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,\n",
        "                                               test_size=0.2,\n",
        "                                               random_state=42,\n",
        "                                               shuffle=True)\n",
        "\n",
        "#순서중요 학습데이터, 검증데이터, 학습 정답 데이터, 검증 정답 데이터!"
      ],
      "metadata": {
        "id": "oMowfKklxfUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "mIJgxzfz0Qyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 선언하기\n",
        "decision_tree_classifier=DecisionTreeClassifier(max_depth=1,\n",
        "                                                random_state=1001\n",
        "                                                )\n",
        "\n",
        "# 학습하기\n",
        "decision_tree_classifier.fit(X=X_train,y=y_train)\n",
        "\n",
        "# 학습 데이터 결과 확인\n",
        "print(f\"학습 데이터 결과: {round(decision_tree_classifier.score(X_train,y=y_train),3)}\")\n",
        "\n",
        "# 검증 데이터 결과 확인\n",
        "print(f\"검증 데이터 결과: {round(decision_tree_classifier.score(X_test,y=y_test),3)}\")"
      ],
      "metadata": {
        "id": "L1gt0vx2k13u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 선언하기 (max_depth 15)\n",
        "decision_tree_classifier=DecisionTreeClassifier(max_depth=15,\n",
        "                                                random_state=1001\n",
        "                                                )\n",
        "\n",
        "# 학습하기\n",
        "decision_tree_classifier.fit(X=X_train,y=y_train)\n",
        "\n",
        "# 학습 데이터 결과 확인\n",
        "print(f\"학습 데이터 결과: {round(decision_tree_classifier.score(X_train,y=y_train),3)}\")\n",
        "\n",
        "# 검증 데이터 결과 확인\n",
        "print(f\"검증 데이터 결과: {round(decision_tree_classifier.score(X_test,y=y_test),3)}\")"
      ],
      "metadata": {
        "id": "LVbUq_dt1ZZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 선언하기 (max_depth 30)\n",
        "decision_tree_classifier=DecisionTreeClassifier(max_depth=30,\n",
        "                                                random_state=1001\n",
        "                                                )\n",
        "\n",
        "# 학습하기\n",
        "decision_tree_classifier.fit(X=X_train,y=y_train)\n",
        "\n",
        "# 학습 데이터 결과 확인\n",
        "print(f\"학습 데이터 결과: {round(decision_tree_classifier.score(X_train,y=y_train),3)}\")\n",
        "\n",
        "# 검증 데이터 결과 확인\n",
        "print(f\"검증 데이터 결과: {round(decision_tree_classifier.score(X_test,y=y_test),3)}\")"
      ],
      "metadata": {
        "id": "P8hzvkeQ1aHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "제일 낮았던 수치는 Max depth 1이었다.\n"
      ],
      "metadata": {
        "id": "dvatrBSQ1uQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### max_feature 파라미터를 1,2,3, 으로 모델을 만들어보고 valiation score가 가장 높은 max_feature를 작성하라. (단, random_state=1001,max_depth는 1로 고정)\n",
        "\n"
      ],
      "metadata": {
        "id": "Nmkvhh0Z1x34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 선언하기 (max_depth 1, max_feature =1)\n",
        "decision_tree_classifier=DecisionTreeClassifier(max_depth=1,\n",
        "                                                random_state=1001,\n",
        "                                                max_features=1\n",
        "                                                )\n",
        "\n",
        "# 학습하기\n",
        "decision_tree_classifier.fit(X=X_train,y=y_train)\n",
        "\n",
        "# 학습 데이터 결과 확인\n",
        "print(f\"학습 데이터 결과: {round(decision_tree_classifier.score(X_train,y=y_train),3)}\")\n",
        "\n",
        "# 검증 데이터 결과 확인\n",
        "print(f\"검증 데이터 결과: {round(decision_tree_classifier.score(X_test,y=y_test),3)}\")"
      ],
      "metadata": {
        "id": "_SFrS6pN19Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 선언하기 (max_depth 1, max_feature =2)\n",
        "decision_tree_classifier=DecisionTreeClassifier(max_depth=1,\n",
        "                                                random_state=1001,\n",
        "                                                max_features=2\n",
        "                                                )\n",
        "\n",
        "# 학습하기\n",
        "decision_tree_classifier.fit(X=X_train,y=y_train)\n",
        "\n",
        "# 학습 데이터 결과 확인\n",
        "print(f\"학습 데이터 결과: {round(decision_tree_classifier.score(X_train,y=y_train),3)}\")\n",
        "\n",
        "# 검증 데이터 결과 확인\n",
        "print(f\"검증 데이터 결과: {round(decision_tree_classifier.score(X_test,y=y_test),3)}\")"
      ],
      "metadata": {
        "id": "ky46U-uH95f9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 선언하기 (max_depth 1, max_feature =3)\n",
        "decision_tree_classifier=DecisionTreeClassifier(max_depth=1,\n",
        "                                                random_state=1001,\n",
        "                                                max_features=3\n",
        "                                                )\n",
        "\n",
        "# 학습하기\n",
        "decision_tree_classifier.fit(X=X_train,y=y_train)\n",
        "\n",
        "# 학습 데이터 결과 확인\n",
        "print(f\"학습 데이터 결과: {round(decision_tree_classifier.score(X_train,y=y_train),3)}\")\n",
        "\n",
        "# 검증 데이터 결과 확인\n",
        "print(f\"검증 데이터 결과: {round(decision_tree_classifier.score(X_test,y=y_test),3)}\")"
      ],
      "metadata": {
        "id": "PEw-1e4o95dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "가장 높았던 max_feature는 1이다."
      ],
      "metadata": {
        "id": "MrqJhAwj95aA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 앙상블\n",
        "\n",
        "다수의 기본 모델을 생성하고 결합하여 하나의 새로운 모델을 생성하는 것\n",
        "\n",
        "다수의 모델을 결합하기에 일반 단일 모델보다 일반적으로 성능이 우수하다.\n",
        "\n",
        "또한 편향과 분산을 모두 적절히 고려하기에 과적합(또는 과소적합) 방지에 용이\n",
        "\n",
        "두가지 고려할 점은 어떤 모델을 사용할 것인가?와 어떻게 결합할 것인지이다.\n",
        "\n",
        "1. 어떤 모델을 사용할 것인지를 고려하여 성능 개선에 효과적인 모델을 선택해서 결합한다.\n",
        "\n",
        "  대표적인 모델이 RandomForest와 Gradient Boosting이다.\n",
        "\n",
        "  해당 모델은 의사결정나무를 기본 모델로 결합한 알고리즘이다.\n",
        "\n",
        "2. 어떻게 결합할 것인지를 고려하여 성능 개서네 효과적인 방법을 선택\n",
        "\n",
        "  결합하는 앙상블 기법에는 보팅,배깅,부스팅이 있다.\n",
        "\n",
        "  RandomForest는 의사결정나무를 병렬로 결합한 배깅 모델, Gradient Boosting은 의사결정나무를 순차적으로 결합한 부스팅 모델이다.\n",
        "\n"
      ],
      "metadata": {
        "id": "Hy5QaGrY-K_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 보팅 이해하기\n",
        "\n",
        "각각 다른 알고리즘을 이용한 모델을 결합하는 방식\n",
        "\n",
        "여러 모델의 결과를 기반으로 투표에 의해 결과를 도출한다.\n",
        "\n",
        "보팅은 하드 보팅과 소프트 보팅으로 나뉜다.\n",
        "\n",
        "1. 하드 보팅은 각 모델의 결과 중 가장 많이 분류된 결과로 최종 결과를 선정하는 방법\n",
        "\n",
        "  예를 들어, 모델 1은 사과를 분류해냈고, 모델 2는 바나나를 분류, 모델 3은 사과를 분류를 했다면, 다수결 또는 많이 분류된 결과로 사과로 최종적인 결괏값을 내보냅니다.\n",
        "\n",
        "  이것이 하드보팅입니다.\n",
        "\n",
        "2. 반면 소프트 보팅은 각 모델별 예측한 확률값의 평균으로 최종값을 선정하는 방법\n",
        "\n",
        "  각 모델은 각 카테고리별 예측 확률을 출력하는 것을 확인한다.\n",
        "\n",
        "  이때 소프트 보팅 기반 앙상블 모델은 3개의 모델이 출력한 각 카테고리의 확률값 평균으로 최종 확률값을 계산하고 최종 확률값이 가장 높은 바나나를 출력한다.\n",
        "\n"
      ],
      "metadata": {
        "id": "mG4nsi7C-K3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 배깅 이해하기\n",
        "\n",
        "배깅은 Boost Aggregating의 줄임말로, 부트스트랩 기반 샘플링 기법을 통해 하나의 알고리즘을 학습하여 생성된 여러 모델의 결과를 결합하는 알고리즘이다.\n",
        "\n",
        "1. 학습 데이터로부터 부트스트랩 샘플링을 진행하여 부트스트랩 데이터 생성\n",
        "\n",
        "2. 각 부트스트랩 데이터로 다수의 개별 모델을 학습한다.\n",
        "\n",
        "3. 최종 예측을 위해 보팅을 진행한다.\n",
        "\n",
        "배깅은 복원 샘플링을 통해 최종 모델의 분산을 줄여줌으로써 예측력을 향상하며, 병렬 학습이 가능하다.\n",
        "\n",
        "대표적인 알고리즘으로 랜덤포레스트가 있음.\n",
        "\n"
      ],
      "metadata": {
        "id": "zPqh9IhY-K1i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 부스팅 이해하기\n",
        "\n",
        "예측력이 약한 모델 여러 개를 순차적으로 연결하여 예측력이 강한 모델을 만드는 앙상블 방법\n",
        "\n",
        "부스팅은 모델을 직렬로 결합하여 앞선 모델이 예측한 것 중 틀린 데이터에 가중치를 부여하여 틀린 데이터를 더 잘 맞히도록 학습한다.\n",
        "\n",
        "1. 학습 데이터의 관측치를 동일한 가중치를 세팅하여 학습을 진행하고 모델 예측을 수행\n",
        "\n",
        "2. 모델 예측에 의해 오분류된 관측치에는 높은 가중치를 부여, 정분류된 관측치에는 낮은 가중치를 부여하여 학습 데이터를 다시 샘플링하고 학습을 진행\n",
        "\n",
        "3. 마지막으로 각 모델의 예측 결과를 결합할 때, 각 모델에 가중치를 주어 가중 평균을 계산하는 방식으로 최종값 출력\n",
        "\n",
        "AdaBoost Gradient Boosting, XGBoost, LIghtGBM"
      ],
      "metadata": {
        "id": "fR6QBvXN-Kzx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 랜덤포레스트"
      ],
      "metadata": {
        "id": "ScUSnY-VFFAb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 랜던 포레스트 실습하기\n",
        "\n",
        "의사결정나무와 랜덤 포레스트 2가지 모델을 만들고 비교해서 모델별 특징과 학습 방법을 알아보자.\n",
        "\n",
        "sklearn.ensemble RandomForestClassifier 클래스\n",
        "\n",
        "하이퍼파라미터\n",
        "- max_depth: 깊어질 수 있는 최대 깊이\n",
        "- n_estimators: 앙상블하는 트리의 개수\n",
        "- max_features: 최대로 사용할 feature 개수\n",
        "- min_samples_split: 트리가 분할할 때 최소 샘플의 개수\n",
        "\n"
      ],
      "metadata": {
        "id": "Z0dwIfJMFI0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터 준비하기\n"
      ],
      "metadata": {
        "id": "A43rZuqeGQ7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tensorflow 라이브러리 설치\n",
        "!pip install tensorflow\n",
        "\n",
        "# tensorflow에서 제공하는 데이터셋 mnist 불러오기\n",
        "from tensorflow.keras.datasets.mnist import load_data\n",
        "\n",
        "# load_data로 데이터할당\n",
        "(x_train,y_train),(x_test,y_test)=load_data()\n",
        "\n",
        "# 손 글씨 데이터는 이미지라 3차원 행렬\n",
        "print(\"변경 전 =\", x_train.shape)\n",
        "\n",
        "# 3c차원 행렬을 2차원으로 변경\n",
        "X_train=x_train.reshape(-1,784)\n",
        "X_test=x_test.reshape(-1,784)\n",
        "\n",
        "# 변경 결과확인하기\n",
        "print(\"변경 후 = \", X_train.shape)"
      ],
      "metadata": {
        "id": "2LUHxjSyGQ5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 의사 결정 나무 모델링하기\n"
      ],
      "metadata": {
        "id": "NtjPksY3GQ3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 의사결정나무 라이브러리 불러오기\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 의사결정나무 학습하기\n",
        "dct=DecisionTreeClassifier(random_state=0)\n",
        "dct.fit(X_train,y_train)\n",
        "\n",
        "# 의사결정나무 결과 확인\n",
        "acc_train_dct=dct.score(X_train,y_train)\n",
        "acc_test_dct=dct.score(X_test,y_test)\n",
        "\n",
        "print(f\"학습 결과 {acc_train_dct}, 검증 결과 {acc_test_dct}\")"
      ],
      "metadata": {
        "id": "P-jalwTbGQ1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 랜덤 포레스트 모델링 및 결과 비교하기"
      ],
      "metadata": {
        "id": "AJpdH2uqGQzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤 포레스트 불러오기\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 랜던 포레스트 선언 및 학습하기\n",
        "rfc=RandomForestClassifier(random_state=0)\n",
        "rfc.fit(X_train,y_train)\n",
        "\n",
        "# 랜덤 포레스트 결과보기\n",
        "acc_train_rfc=rfc.score(X_train,y_train)\n",
        "acc_test_rfc=rfc.score(X_test,y_test)\n",
        "\n",
        "# 학습 결과 수치로 출력하기\n",
        "print(f\"의사결정나무: train_acc = {round(acc_train_dct,3)}, test_acc = {round(acc_test_dct,3)}\")\n",
        "print(f\"랜덤 포레스트: train_acc = {round(acc_train_rfc,3)}, test_acc = {round(acc_test_rfc,3)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LjJGPR6cGQxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤 포레스트 결과를 토대로 비교 그래프 그리기\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# x축 정의하기\n",
        "acc_list_x = [\"dct_train\",\"dct_test\",'rfc_train','rfc_test']\n",
        "\n",
        "# y축 정의하기\n",
        "acc_list_y = [acc_train_dct,acc_test_dct,acc_train_rfc,acc_test_rfc]\n",
        "\n",
        "# 막대 그래프 차트 색 정의하기\n",
        "colors = ['orange','orange','blue','blue']\n",
        "\n",
        "# 막대 그래프 설정하기\n",
        "plt.bar(acc_list_x,acc_list_y,color=colors)\n",
        "\n",
        "# 화면 출력\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4crpvoZdGQvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 랜덤 포레스트와 의사결정나무 비교\n",
        "\n",
        "랜덤 포레스트의 하이퍼 파라미터를 튜닝하여 의사결정나무와 유사한 결과가 나오도록 해보자\n",
        "\n",
        "랜덤 포레스트와 의사결정나무의 차이저믈 이론에서 유추해보면 다음과같다.\n",
        "\n",
        "1. 부트스트래핑 활용 유무\n",
        "2. 모델의 결합\n",
        "\n",
        "이번 실습에서 부트스트랩을 제한하고, 모델의 개수를 1개로 지정하여 의사결정나무의 형태로 만들고 결과를 보자\n"
      ],
      "metadata": {
        "id": "iUo9gHcZGQtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 의사결정나무 결과와 동일하게 랜덤 포레스트 구성하기\n",
        "rft=RandomForestClassifier(\n",
        "    random_state=0,\n",
        "\n",
        "    # 나무 개수를 1개로 설정하기\n",
        "    n_estimators=1,\n",
        "\n",
        "    # 부트스트랩 제한\n",
        "    bootstrap=False,\n",
        "\n",
        "    # max_features는 의사결정나무로 변경\n",
        "    max_features=None\n",
        ")\n",
        "rft.fit(X_train,y_train)\n",
        "\n",
        "# 학습 결과 저장하기\n",
        "acc_train_rfc=rft.score(X_train,y_train)\n",
        "acc_test_rfc=rft.score(X_test,y_test)\n",
        "acc_train_dtc=dct.score(X_train,y_train)\n",
        "acc_test_dtc=dct.score(X_test,y_test)\n",
        "\n",
        "# 의사결정나무 & 랜덤 포레스트가 유사한 결과를 출력하는지 비교\n",
        "print(f\"의사결정나무 : train_acc = {round(acc_train_dtc,3)}, test_acc = {round(acc_test_dtc,3)}\")\n",
        "print(f\"랜덤 포레스트: train_acc = {round(acc_train_rfc,3)}, test_acc = {round(acc_test_rfc,3)}\")"
      ],
      "metadata": {
        "id": "f80Alui4GQYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Max_features 값을 40,50,60 으로 변경해보고 가장 좋은 결과값을 작성하세요."
      ],
      "metadata": {
        "id": "VwaA4VOBQSk1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Max_features 값에 따른 MNIST 분류 스코어 알아보기"
      ],
      "metadata": {
        "id": "m_R41QawRkeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train : {X_train.shape}\")\n",
        "print(f\"y_train: {y_train.shape}\")\n",
        "\n",
        "print(f\"X_test: {X_test.shape}\")\n",
        "print(f\"y_test: {y_test.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "e1Vi78c6Q_2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rft40=RandomForestClassifier(max_features=40,\n",
        "                             random_state=42\n",
        "                             )\n",
        "\n",
        "rft50=RandomForestClassifier(max_features=50,\n",
        "                             random_state=42\n",
        "                             )\n",
        "rft60=RandomForestClassifier(max_features=60,\n",
        "                             random_state=42\n",
        "                             )\n",
        "\n",
        "rft40.fit(X_train,y_train)\n",
        "rft50.fit(X_train,y_train)\n",
        "rft60.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "7OU6Goe7G4e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "분류 점수 보기"
      ],
      "metadata": {
        "id": "3WusZ_YTSZpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"acc_Score for Train RFT40: {rft40.score(X_test,y_test)}\")\n",
        "print(f\"acc_Score for Test RFT40: {rft40.score(X_test,y_test)}\")\n",
        "\n",
        "print(f\"acc_Score for Train RFT50: {rft50.score(X_test,y_test)}\")\n",
        "print(f\"acc_Score for Test RFT50: {rft50.score(X_test,y_test)}\")\n",
        "\n",
        "print(f\"acc_Score for Train RFT60: {rft60.score(X_test,y_test)}\")\n",
        "print(f\"acc_Score for Test RFT60: {rft60.score(X_test,y_test)}\")"
      ],
      "metadata": {
        "id": "Wa_iHAnHRwe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 그래디언트 부스팅\n",
        "\n",
        "부스팅 계열의 알고리즘으로, 트리 기반의 모델을 직렬로 연결하여 앞선 모델이 예측한 것 중 틀린 데이터에 가중치를 부여하여 더 잘 학습되도록 하는 알고리즘\n",
        "\n",
        "- 직렬로 연결하여 모델이 예측한 것 중 틀린 데이터에 가중치를 부여!\n",
        "\n",
        "- 트리기반모델을 직렬로 연결 !\n",
        "\n",
        "배깅은 병렬로 모델을 연결하여 학습이 진행되기에, 각각의 모델 생성이 가능하지만,\n",
        "\n",
        "부스팅 계열의 알고리즘은 순차적으로 학습이 진행된다.\n",
        "\n",
        "따라서 부스팅 계열의 알고리즘이 배깅의 알고리즘보다 학습이 더 오래 지속된다.\n",
        "\n",
        "그러나 부스팅 계열의 장점은 앞선 모델을 개선하는 방향으로 학습하기 때문에, 어려운 데이터에 대해 좀 더 좋은 성능을 가진 모델을 만들어낼 수 있다.\n",
        "\n",
        "그래디언트 부스팅은 이진 분류나 연속적인 수치 예측에도 잘 작동한다.\n",
        "\n"
      ],
      "metadata": {
        "id": "A1eaH5q3TPka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 그래디언트 부스팅 실습하기\n",
        "\n",
        "sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "하이퍼파라미터\n",
        "- learning rate: 학습률\n",
        "- n_estimator: 부스팅 스테이지 수, default =100 (n_estimator가 커질수록 과대적합 확률이 높음)\n",
        "- max_depth: 트리의 깊이, 과대적합 방지용, default=3\n",
        "- subsample: 샘플 사용 비율, 과대적합 방지용, default=1.0\n",
        "- max_features: 최대로 사용할 수 있는 feature의 비율, 과대적합 방지용, default=1.0\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gBe7310AYdv7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터 준비하기"
      ],
      "metadata": {
        "id": "xTNygWz8YdsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tensorflow에서 데이터 불러오기\n",
        "from tensorflow.keras.datasets.mnist import load_data\n",
        "\n",
        "# 그래프 라이브러리 불러오기\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 데이터 불러오기\n",
        "(X_train,y_train),(X_test,y_test)=load_data()\n",
        "\n",
        "# 학습 시간을 고려하여 데이터 10000건, 2000건만 사용\n",
        "X_train=X_train[:5000]\n",
        "y_train=y_train[:5000]\n",
        "\n",
        "X_test=X_test[:2000]\n",
        "y_test=y_test[:2000]\n",
        "\n",
        "print(f\"X_train.shape :{X_train.shape}\")\n",
        "print(f\"X_test.shape: {X_test.shape}\")\n",
        "\n",
        "print(f\"y_train.shape: {y_train.shape}\")\n",
        "print(f\"y_test.shape: {y_test.shape}\")\n",
        "\n",
        "# 샘플 데이터 이미지 확인하기\n",
        "print(f'X_train[1]: {X_train[1]}')\n",
        "\n",
        "plt.imshow(X_train[1],cmap='gray') # figure에 이미지를 그린다.\n",
        "plt.show() # figure를 보여준다"
      ],
      "metadata": {
        "id": "ak45lbyBYdom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습을 위한 2차원 행렬 변경\n",
        "print(f\"X_train.shape: {X_train.shape}\")\n",
        "X_train=X_train.reshape(-1,784)\n",
        "X_test=X_test.reshape(-1,784)\n",
        "print(f\"X_train.shape{X_train.shape}\")"
      ],
      "metadata": {
        "id": "UfrC2-ozYdky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 알고리즘별 학습 및 결과 비교하기"
      ],
      "metadata": {
        "id": "mYtVcNsRYdgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 의사결정나무, 랜덤 포레스트, 그래디언트 부스팅 라이브러리 불러오기\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# 의사결정나무 불러오기 및 학습하기\n",
        "dct=DecisionTreeClassifier(random_state=0)\n",
        "dct.fit(X_train,y_train)\n",
        "\n",
        "# 의사결정나무 학습 결과 저장하기\n",
        "acc_train_dct=dct.score(X_train,y_train)\n",
        "acc_test_dct=dct.score(X_test,y_test)\n",
        "\n",
        "# 랜덤 포레스트 불러오기 및 학습하기\n",
        "rfc=RandomForestClassifier(random_state=0)\n",
        "rfc.fit(X_train,y_train)\n",
        "\n",
        "# 랜덤 포레스트 학습 결과 저장하기\n",
        "acc_train_rfc=rfc.score(X_train,y_train)\n",
        "acc_test_rfc=rfc.score(X_test,y_test)\n",
        "\n",
        "# 그래디언트 부스팅 불러오기 및 학습하기\n",
        "gbc=GradientBoostingClassifier(random_state=0,verbose=1)\n",
        "gbc.fit(X_train,y_train)\n",
        "\n",
        "# 그래디언트 부스팅 학습결과 저장하기\n",
        "acc_train_gbc=gbc.score(X_train,y_train)\n",
        "acc_test_gbc=gbc.score(X_test,y_test)\n",
        "\n",
        "# 각 알고리즘별 성능 비교하기\n",
        "print(f\"의사 결정 나무: train_acc={round(acc_train_dct,3)}, test_acc={round(acc_test_dct,3)}\")\n",
        "print(f\"의사 결정 나무: train_acc={round(acc_train_rfc,3)}, test_acc={round(acc_test_rfc,3)}\")\n",
        "print(f\"의사 결정 나무: train_acc={round(acc_train_gbc,3)}, test_acc={round(acc_test_gbc,3)}\")"
      ],
      "metadata": {
        "id": "Ckl9RWokYdeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 딥러닝 프레임워크 텐서플로우\n",
        "\n"
      ],
      "metadata": {
        "id": "FhXO65yHYdaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 심층신경망으로 항공사 고객 만족 분류 모델을 구현해 봅니다."
      ],
      "metadata": {
        "id": "t1CZvysrNs7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 불러오기 및 확인하기\n"
      ],
      "metadata": {
        "id": "Gac8ikYjRiEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 불러오기\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "# 경고 메세지를 무시하도록 설정하기\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# csv 파일에서 데이터를 로드해서 데이터프레임으로 저장하기\n",
        "df=pd.read_csv(\"/content/Invistico_Airline.csv\")\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "id": "BsZzxSWBYdW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "bDGEbJxMYdTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 요약 통계량 확인하기 (min,max,std,mean,count)\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "ti_XDpgQQ2k4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 확인하기\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "14jeltiqQ2jJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arrivial Delay in Minutes 393개 결측치 존재"
      ],
      "metadata": {
        "id": "Xlsun0I3RaIo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 전처리하기\n",
        "\n",
        "신경망 모델의 입력데이터는 결측치가 없어야하고, 기본적으로 수치형 데이터를 사용합니다.\n",
        "\n",
        "그러므로, 범주형 데이터를 수치형 데이터로 변환하는 인코딩 작업을 하며,\n",
        "수치형 데이터도 모델 성능을 높이기 위해 데이터 스케일링 등의 변환 작업이 요구된다.\n",
        "\n"
      ],
      "metadata": {
        "id": "f7tDqbA9Q2hK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 결측치 처리하기\n",
        "\n",
        "sklearn의 SimpleImputer 객체를 사용하여 도착 지연 시간(Arrival Delay  in Minutes) 칼럼에 있는 결측치를 평균값으로 치환"
      ],
      "metadata": {
        "id": "m89o4f6QQ2fX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SimpleImputer 객체로 결측치 대체하기\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "mean_imputer=SimpleImputer(strategy=\"mean\")\n",
        "df[\"Arrival Delay in Minutes\"] = mean_imputer.fit_transform(df[[\"Arrival Delay in Minutes\"]])\n",
        "\n",
        "df.isnull().sum()\n",
        "# 결측치가 사라짐"
      ],
      "metadata": {
        "id": "KeYsXbfhQ2db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터 인코딩하기\n",
        "Object 칼럼의 유형을 String 유형으로 변경하기"
      ],
      "metadata": {
        "id": "BG5Y_0XkQ2bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Object 칼럼 유형을 string으로 변경하기\n",
        "cols=['satisfaction','Gender','Customer Type','Type of Travel','Class']\n",
        "df[cols]=df[cols].astype(str)"
      ],
      "metadata": {
        "id": "OX8aXfyMQyrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 범주형 데이터를 수치값으로 변경하기\n",
        "df['satisfaction'].replace(['dissatisfied','satisfied'],[0,1],inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "XWgzNC50YdPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Gender\"].value_counts()"
      ],
      "metadata": {
        "id": "nZWN0ruiXtdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 순서형 인코딩하기\n",
        "categories=pd.Categorical(\n",
        "    df['Class'],\n",
        "    categories=['Eco','Eco Plus','Business'],\n",
        "    ordered=True\n",
        ")\n",
        "labels,unique=pd.factorize(categories,sort=True)\n",
        "df['Class'] = labels\n",
        "df['Class']"
      ],
      "metadata": {
        "id": "jAbunuNlYdLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "좌석 등급(Class) 칼럼은 순서를 고려해 정수 1~N으로 순서형 인코딩을 합니다.\n",
        "\n",
        "'Eco','Eco Plus','Business'값이 0,1,2로 변환된다.\n",
        "\n",
        "순서형 인코딩은 pd.Categorical"
      ],
      "metadata": {
        "id": "IXQmAuGoVl-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels,unique"
      ],
      "metadata": {
        "id": "QZQ8ZSbFVFXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "범주형 데이터인 성별(Gender), 고객 유형(Customer Type), 여행 유형(Type of Travel)\n",
        "칼럼은 원핫 인코딩을 적용하기\n",
        "원핫인코딩 0과 1의 벡터로만 표현하는 기법이다.\n",
        "범주의 수만큼 벡터의 수가 생성되므로, 각 범주가 새로운 특성이 된다."
      ],
      "metadata": {
        "id": "WotkI2LZYc0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols=['Gender','Customer Type','Type of Travel']\n",
        "df=pd.get_dummies(df,columns=cat_cols)"
      ],
      "metadata": {
        "id": "qScRPcvbYbhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "Ll0Pr8DzbJtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터세트 분리하기"
      ],
      "metadata": {
        "id": "uYtxIQmUbkIy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터세트를 입력(X)과 레이블(y)로 분리하고, 훈련 데이터세트와 검증 데이터세트로 분리합니다.\n",
        "\n",
        "데이터세트는 test_size에 지정한 비율로 분리된다."
      ],
      "metadata": {
        "id": "IWx3TalAboI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터세트를 입력(X)과 레이블(y)로 분리하기\n",
        "X=df.drop(['satisfaction'],axis=1)\n",
        "y=df['satisfaction'].reset_index(drop=True)\n",
        "print(y)\n",
        "# 데이터세트를 훈련데이터와 검증 데이터로 분리하기\n",
        "X_train,X_test,y_train,y_test=train_test_split(\n",
        "    X,y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(f\"훈련 데이터세트 크기: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print(f\"검증 데이터세트 크기: X_test: {X_test.shape}, y_test: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "WcKsCTecboNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터 스케일링하기 MinMaxScaler, StandardScaler"
      ],
      "metadata": {
        "id": "F1kb_vzkg-eK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "특성별로 데이터의 스케일이 다르면 딥러닝이 잘 동작하지 않을 수 있습니다.\n",
        "\n",
        "따라서 데이터 스케일링 작업을 통해 모든 특성의 범위를 유사하게 만들어줘야합니다.\n",
        "\n",
        "사이킷런 MinMaxScaler 객체로 데이터의 최소값,최댓갑슬 이용하여 데이터를 특정범위 (0~1사이)로 스케일링하여 특성을 정규화합니다.\n",
        "\n",
        "StandardScaler 객체도 스케일링에 많이 사용된다.\n",
        "\n",
        "StandardScaler는 특성들의 평균을 0, 분산을 1로 스케일링하여 정규분포로 만드는 표준화를 한다.\n",
        "\n"
      ],
      "metadata": {
        "id": "MP5uyrqVhAm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# 데이터 정규화하기\n",
        "scaler=MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train=scaler.transform(X_train)\n",
        "X_val=scaler.transform(X_test)\n",
        "\n",
        "print(X_train)"
      ],
      "metadata": {
        "id": "RLUeFEL5kkeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 심층신경망 모델 생성하기\n",
        "\n",
        "입력데이터는 25개(satisfaction 제외), 은닉층은 여러개, 출력은 1개인 이진 분류를 위한 심층 신경망 (DNN) 모델을 구성합니다.\n",
        "\n",
        "은닉층의 활성화 함수는 'ReLU'를 사용한다.\n",
        "\n",
        "마지막 층의 활성화 함수는 출력이 1개인 이진 분류모델이므로 'sigmoid'를 사용합니다.\n"
      ],
      "metadata": {
        "id": "aetStxFyYRiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 불러오기\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input,Dense,Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# 모델 시드 고정하기\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Keras의 Sequential 객체로 딥러닝 모델 구현\n",
        "initializer=tf.keras.initializers.GlorotUniform(seed=42) # 모델 시즈 고정하기\n",
        "model=Sequential()\n",
        "model.add(Dense(32,activation='relu',input_shape=(25,),kernel_initializer=initializer))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "89Rj1DqiYRgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "lVXQ8UMRrOnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "가중치 초기화(initialization)를 위해 사용되는 초기화 방법 중 하나인 Glorot 초기화(Xavier 초기화)를 설정하는 코드입니다\n",
        "\n",
        "Glorot 초기화는 다음과 같은 주요 특징을 가지고 있습니다:\n",
        "\n",
        "- 가중치 초기화의 분산을 조절하여 그레디언트 소실 및 폭주 문제를 완화합니다.\n",
        "- 입력 및 출력 유닛의 수에 따라 적절한 초기화 스케일을 자동으로 조정합니다.\n",
        "- 일반적으로 sigmoid 또는 tanh 활성화 함수와 함께 사용할 때 효과적입니다."
      ],
      "metadata": {
        "id": "1ENMF3g7qDbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 컴파일하기"
      ],
      "metadata": {
        "id": "RG4SEy7QqDTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 학습시킬 최적화 방법, Loss 함수, 평가 방법등을 설정\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "CiLgf-E_YRcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 학습하기\n",
        "\n",
        "EarlyStopping 의 주요 인자\n",
        "\n",
        "- monitor: 학습 조기 종료를 위한 성능 모니터링 도구, val_loss나 val_accuracy가 주로 사용되며 기본값은 val_loss\n",
        "\n",
        "- min_delta: 개선되고 있다고 판단하기 위한 최소 변화량\n",
        "\n",
        "- patience: 성능 향상을 몇 번의 에포크 동안 기다릴지 설정하며 기본값은 0\n",
        "\n",
        "- verbose: 얼마나 자세하게 정보를 표출할 것인가를 지정, 가능한 값은 0 1 2\n",
        "\n",
        "- mode: 성능 모니터링 도구의 개선 판단 기준으로, monitor 설정 값에 따라\n",
        "val_loss면 min, val_accuracy면 max로 설정한다.\n",
        "\n",
        "\n",
        "- restore_best_weights: 관찰 항목의 가장 좋은 값을 가지는 에포크의 모델 가중치 복원 여부. 기본값은 False로 학습에포크의 마지막 가중치를 보존합니다.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kpVCI2ttYRav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 학습시 너무 많은 에포크 수는 과대적합을 발생시킬 수 있다.\n",
        "\n",
        "이를 방지하기 위한 방법으로 조기종료 (EalryStopping) 이 있다 조기 종료는 검증 데이터세트에서 성능이 더이상 증가하지 않으면\n",
        "중단하는 방법으로 model.fit함수의 callback 매개변수에 넣어주면 조기 종료된다.\n",
        "\n"
      ],
      "metadata": {
        "id": "xLprznLHxl8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습하기\n",
        "es=EarlyStopping(monitor='val_loss',min_delta=0,patience=10,verbose=1,restore_best_weights=True)\n",
        "history=model.fit(X_train,y_train,epochs=100,batch_size=128,verbose=1,validation_data=(X_val,y_test),callbacks=[es])\n",
        "\n",
        "# validation loss가 10번 이상 개선되지 않으면 학습을 중단하고, 가장 성능이 좋았을 때의 가중치를 사용, 훈련과정의 loss, accuracy를 history에 저장"
      ],
      "metadata": {
        "id": "W6H-GpLSYRY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 훈련과정 시각화하기\n",
        "\n",
        "> fit() 메소드는 history 객체를 반환합니다.\n",
        "\n",
        "history.history 속성은 모델의 훈련과정에서 에포크에 따른 정확도와 같은 성능 지표와 손실값을 기록 그리고 검증 지표와 손실값도 기록\n",
        "\n",
        "accuracy,val_accuracy,loss,val_loss를 그래프로 출력하여 시각화\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "72HuMQa4e4os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 훈련 과정 정확도 시각화하기\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(['Train',\"Validation\"],loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 훈련 과정 손실 시각화\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title(\"Model loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend([\"Train, Validation\"],loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "goNStf-ee--E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}